{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас будем решать задачу классификации текста - вещь приближенная к реальности. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T07:18:43.629299Z",
     "start_time": "2019-04-17T07:18:43.619001Z"
    }
   },
   "source": [
    "как нам это делать?\n",
    "\n",
    "давайте представим задачу попроще - задача классификации отзыва на каком нибудь интернет магазине - люди приходят и пишут комментарии про то как им товар. манеджеру очень-очень хочется чтобы все были довольны, и если кто-то расстроен, то он отправит кого-нибудь из поддержки на помощь. \n",
    "\n",
    "Как бы помочь менеджеру выявлять грустных клиентов по их отзывам? Классифицировать их на два класса - хороший отзыв или плохой!\n",
    "\n",
    "_самый простой способ это делать - просто закостылить if-чиками программу которая будет ходить по всем отзывам и смотреть, есть ли в них слова из группы {огонь, рад, счастлив, устраивает, замечательный и тд} и из группы {расстроен, плохой, ненавижу, грустно, печально, итд} и в зависимости от этого классифицировать отзывы на две группы._\n",
    "\n",
    "например отзыв: \"я рад что купил ваш товар потому что без него не могу теперь\" отнесется к положительному классу, а отзыв \"больше никогда у вас ничего не куплю, последний товар был плохим и я очень расстроен вашим сервисом\" - к негативному отзыву.\n",
    "\n",
    "____\n",
    "\n",
    "но тут есть две проблемы:\n",
    "\n",
    "1) нам сложно выделять все позитивные и негативные слова, все не перечислить, нам надо писать код и дать решение, а не составлять словарь слов с различными окрасками.\n",
    "\n",
    "2) слова из позитивной группы могут встречаться в негативном отзыве и наоборот, может быть что 3 слова из позитивной группы слов встретились в отзыве (рад, нормально, хорошо), а из негативной только два (плохо, не буду), и не всегда ясно что с таким делать - всегда можно подобрать такой кейс где надо относить такой пример к негативному, а не позитивному, потму что разные слова могут вносить разный вклад в результат (какие то слова более ярко окрашивают \"настроение\" предложения)\n",
    "\n",
    "\n",
    "Призовем на помощь машинное обучение!\n",
    "\n",
    "\n",
    "что мы можем сделать? давайте попросим менеджера разметить по 300-500-1000 отзывов на плохие и хорошие категории, и обучим на этом модель, чтобы она сама подбирала веса для слов.\n",
    "\n",
    "Скажем, что у каждого слова есть вес $\\Large{w}$ - позитивный или негативный (например 100 или -1.234), пусть машинное обучение само подбирает важность и окрас каждого слова и оценит вклад слова в результат. \n",
    "\n",
    "Как будет выглядеть наш классификатор?\n",
    "Возьмем логистическую регрессию \n",
    "\n",
    "$$P(cat=positive) = \\sigma{(< X, w>)} $$\n",
    "\n",
    "где $\\sigma(x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x} } $\n",
    "\n",
    "X - бинарный вектор, в котором 1 - значит что такое то слово присутствует, а 0 - что отсутствует. \n",
    "\n",
    "Тогда идея классификатора в следующем - подберем и сложим веса для различных слов которые встречаются в отзыве, посмотрим вероятности и предскажем к какому классу это относится! Круто.\n",
    "\n",
    "\n",
    "\n",
    "А теперь давайте решать задачу классификации объявлений одной известной интернет доски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:37:14.436804Z",
     "start_time": "2019-04-15T12:37:14.418730Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:37:18.624380Z",
     "start_time": "2019-04-15T12:37:14.699815Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:37:18.665648Z",
     "start_time": "2019-04-15T12:37:18.637314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312862</td>\n",
       "      <td>Картина</td>\n",
       "      <td>Гобелен. Размеры 139х84см.</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339243</td>\n",
       "      <td>Стулья из прессованной кожи</td>\n",
       "      <td>Продам недорого 4 стула из светлой прессованно...</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6677</td>\n",
       "      <td>Домашняя мини баня</td>\n",
       "      <td>Мини баня МБ-1(мини сауна), предназначена для ...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190544</td>\n",
       "      <td>Эксклюзивная коллекция книг \"Трансаэро\" + подарок</td>\n",
       "      <td>Продам эксклюзивную коллекцию книг, выпущенную...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>372595</td>\n",
       "      <td>Ноутбук aser</td>\n",
       "      <td>Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                              title  \\\n",
       "0   312862                                            Картина   \n",
       "1   339243                        Стулья из прессованной кожи   \n",
       "2     6677                                 Домашняя мини баня   \n",
       "3   190544  Эксклюзивная коллекция книг \"Трансаэро\" + подарок   \n",
       "4   372595                                       Ноутбук aser   \n",
       "\n",
       "                                         description    price  category_id  \n",
       "0                         Гобелен. Размеры 139х84см.   1000.0           19  \n",
       "1  Продам недорого 4 стула из светлой прессованно...   1250.0           22  \n",
       "2  Мини баня МБ-1(мини сауна), предназначена для ...  13000.0           37  \n",
       "3  Продам эксклюзивную коллекцию книг, выпущенную...   4000.0           43  \n",
       "4  Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...  19000.0            1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> нам надо представить каждое объявление в виде набора признаков. с числом price - понятно, это и так признак объявления. однако наши классификаторы не умеют просто так работать с текстом. надо представить текст в виде признаков. какой самый простой способ векторизовать текст?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> представить текст в виде вектора - размерностью число возможных слов, и заполнять значениями сколько раз каждое из слов встретилось в тексте. примерно так же как на картинке ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/assets/feml_0405.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в sklearn для этого есть CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:37:49.607821Z",
     "start_time": "2019-04-15T12:37:24.708973Z"
    }
   },
   "outputs": [],
   "source": [
    "title_vectorizer = CountVectorizer(max_features=1000, binary=True)\n",
    "title_features = title_vectorizer.fit_transform(data.title)\n",
    "\n",
    "descr_vectorizer = CountVectorizer(max_features=1000, binary=True)\n",
    "description_features = descr_vectorizer.fit_transform(data.description)\n",
    "\n",
    "features = sp.hstack([title_features, description_features, data[['price']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:37:50.154593Z",
     "start_time": "2019-04-15T12:37:49.612290Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(features, data.category_id, \n",
    "                                              random_state=241, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:01.726128Z",
     "start_time": "2019-04-15T12:37:50.156230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 1s, sys: 1.27 s, total: 16min 3s\n",
      "Wall time: 16min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = LogisticRegression(C=100)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "y_pred = clf.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:01.748321Z",
     "start_time": "2019-04-15T12:54:01.731418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193855238784975"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yval, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предскажем тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:02.173958Z",
     "start_time": "2019-04-15T12:54:01.749716Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:04.770082Z",
     "start_time": "2019-04-15T12:54:02.176500Z"
    }
   },
   "outputs": [],
   "source": [
    "title_features = title_vectorizer.transform(test.title)\n",
    "description_features = descr_vectorizer.transform(test.description)\n",
    "\n",
    "\n",
    "features = sp.hstack([title_features, description_features, test[['price']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:04.776236Z",
     "start_time": "2019-04-15T12:54:04.771628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54361, 2001)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:04.864466Z",
     "start_time": "2019-04-15T12:54:04.778588Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сохраним в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:54:05.042211Z",
     "start_time": "2019-04-15T12:54:04.866137Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': test.item_id, 'Category':y_pred_test}).to_csv('my_pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что можно сделать еще?\n",
    "\n",
    "> Какие недостатки решения выше у нас есть?\n",
    "\n",
    "\n",
    "> давайте помнить что модель - глупая, она умеет разделять только точки. Хорошо бы нам самим передать ей эти точки так, чтобы глупая модель сама смогла хорошо разделить наши данные. наверное, разные формы слов хорошо было бы представить одним? например \"хорошая\" и \"хороший\" - это в принципе про одно качество, а \"стул\" и \"стулья\" про один предмет. \n",
    "\n",
    "\n",
    "> попробуйте tf-idf, хеширование признаков, что можно сделать с непрерывным признаком, удаление мусорных слов, удаление частотных слов, стемминг или лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "стемминг или лемматизация:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pymorphy2.readthedocs.io/en/0.2/user/index.html\n",
    "\n",
    "https://tech.yandex.ru/mystem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишите вопросы в специальный канал, правила игры вы знаете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
